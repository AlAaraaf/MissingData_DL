{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "numeric_variable_nums = dict([('boston', 12), ('house',8),('sim_1', 0),('sim_2',0), ('sim_1_tiny',0), ('sim_2_tiny',0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate complete data's conditional distributions\n",
    "def generate_cond(dataset, mr, size, sample_id):\n",
    "    complete_data_path = './samples/' + dataset + '/complete_' + str(mr) + '_' + str(size) + '/sample_' + str(sample_id) + '.csv'\n",
    "    data = pd.read_csv(complete_data_path, header=None)\n",
    "\n",
    "    # divide cat/num type\n",
    "    num_index = list(range(data.shape[1] - numeric_variable_nums[dataset], data.shape[1]))\n",
    "    cat_index = list(range(0, data.shape[1] - numeric_variable_nums[dataset]))\n",
    "\n",
    "    # get all possible levels' combination for categorical variable\n",
    "    all_levels = [np.unique(data.iloc[:,i]).tolist() for i in cat_index]\n",
    "    all_levels_comb = list(product(*all_levels[:-1]))\n",
    "\n",
    "    # calculate conditional distributions for complete data\n",
    "    cond_dist_complete = dict.fromkeys(all_levels_comb, None)\n",
    "    for index, item in data.iterrows():\n",
    "        cond = (item[0], item[1], item[2])\n",
    "        if cond_dist_complete[cond] == None:\n",
    "            cond_dist_complete[cond] = [0 for x in range(len(all_levels[-1]))]\n",
    "        cond_dist_complete[cond][int(item[3])] += 1\n",
    "\n",
    "    for key in cond_dist_complete.keys():\n",
    "        denom = sum(cond_dist_complete[key])\n",
    "        cond_dist_complete[key] = [round(x / denom, 3) for x in cond_dist_complete[key]]\n",
    "\n",
    "    return all_levels, all_levels_comb, cond_dist_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output KL divergence for each pair of conditional distribution in one sample\n",
    "def kl_comparison(method, imputed_data_folder, all_levels, all_levels_comb, cond_dist_complete, sample_id, impute_num):\n",
    "    # calculate conditional distributions from imputed datasets\n",
    "    cond_dist_imputed = dict.fromkeys(all_levels_comb, None)\n",
    "    for i in range(impute_num):\n",
    "        current_imputed_dir = imputed_data_folder + 'imputed_' + str(sample_id) + '_' + str(i) + '.csv'\n",
    "        imputed_data = pd.read_csv(current_imputed_dir, header=None)\n",
    "        for index, item in imputed_data.iterrows():\n",
    "            if method == 'cart':\n",
    "                cond = (item[0]-1, item[1]-1, item[2]-1)\n",
    "            else:\n",
    "                cond = (item[0], item[1], item[2])\n",
    "            if cond_dist_imputed[cond] == None:\n",
    "                cond_dist_imputed[cond] = [0 for x in range(len(all_levels[-1]))]\n",
    "            cond_dist_imputed[cond][int(item[3] - 1)] += 1\n",
    "\n",
    "    for key in cond_dist_imputed.keys():\n",
    "        denom = sum(cond_dist_imputed[key])\n",
    "        cond_dist_imputed[key] = [round(x / denom, 3) for x in cond_dist_imputed[key]]\n",
    "\n",
    "\n",
    "    # output comparing KL divergence\n",
    "    from scipy.special import rel_entr\n",
    "    comparison_dict = dict.fromkeys(all_levels_comb, None)\n",
    "    for key in comparison_dict.keys():\n",
    "        comparison_dict[key] = round(sum(rel_entr(cond_dist_complete[key], cond_dist_imputed[key])),6)\n",
    "    average_kl = np.average(list(comparison_dict.values()))\n",
    "    return average_kl, comparison_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average result\n",
    "def average_kl_comparison(dataset, mr, size, sample_num, impute_num, method_list):\n",
    "    metric_avr_kl = pd.DataFrame(columns=['method','sample_id','avr_kl'])\n",
    "    for sample_id in range(sample_num):\n",
    "        all_levels, all_levels_comb, cond_dist_complete = generate_cond(dataset, mr, size, sample_id)\n",
    "        for method in method_list:\n",
    "            imputed_data_folder = './results/' + dataset + '/MCAR_' + str(mr) + '_' + str(size) + '/' + method + '/'\n",
    "            average_kl, kl_dict = kl_comparison(method, imputed_data_folder,all_levels, all_levels_comb, cond_dist_complete, sample_id, impute_num)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sim_1_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete data\n",
    "# readin datasets (complete dataset)\n",
    "dataset = 'sim_1_tiny'\n",
    "mr = 0.3\n",
    "size = 5000\n",
    "sample_id = 0\n",
    "impute_num = 10\n",
    "all_levels, all_levels_comb, cond_dist_complete = generate_cond(dataset, mr, size, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6579264999999999\n",
      "{(0.0, 0.0, 0.0): 0.641552, (0.0, 0.0, 1.0): 0.43908, (0.0, 0.0, 2.0): 0.28599, (0.0, 1.0, 0.0): 0.476044, (0.0, 1.0, 1.0): 0.131686, (0.0, 1.0, 2.0): 0.886153, (1.0, 0.0, 0.0): 0.470688, (1.0, 0.0, 1.0): 0.245293, (1.0, 0.0, 2.0): 0.494988, (1.0, 1.0, 0.0): 0.440291, (1.0, 1.0, 1.0): 0.249321, (1.0, 1.0, 2.0): 1.579883, (2.0, 0.0, 0.0): 0.454457, (2.0, 0.0, 1.0): 0.264683, (2.0, 0.0, 2.0): 1.280886, (2.0, 1.0, 0.0): 0.251879, (2.0, 1.0, 1.0): 0.475506, (2.0, 1.0, 2.0): 2.774297}\n"
     ]
    }
   ],
   "source": [
    "method = 'gain'\n",
    "imputed_data_folder = './results/' + dataset + '/MCAR_' + str(mr) + '_' + str(size) + '/' + method + '/'\n",
    "kl_comparison(method, imputed_data_folder,all_levels, all_levels_comb, cond_dist_complete, sample_id, impute_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025560555555555558\n",
      "{(0.0, 0.0, 0.0): 0.003231, (0.0, 0.0, 1.0): 0.000728, (0.0, 0.0, 2.0): 0.000128, (0.0, 1.0, 0.0): 0.002845, (0.0, 1.0, 1.0): 0.002234, (0.0, 1.0, 2.0): 0.006296, (1.0, 0.0, 0.0): 0.000271, (1.0, 0.0, 1.0): 0.000966, (1.0, 0.0, 2.0): 0.001838, (1.0, 1.0, 0.0): 0.000858, (1.0, 1.0, 1.0): 0.005284, (1.0, 1.0, 2.0): 0.002473, (2.0, 0.0, 0.0): 0.009529, (2.0, 0.0, 1.0): 0.003479, (2.0, 0.0, 2.0): -0.000121, (2.0, 1.0, 0.0): 0.002401, (2.0, 1.0, 1.0): 0.000168, (2.0, 1.0, 2.0): 0.003401}\n"
     ]
    }
   ],
   "source": [
    "method = 'cart'\n",
    "imputed_data_folder = './results/' + dataset + '/MCAR_' + str(mr) + '_' + str(size) + '/' + method + '/'\n",
    "kl_comparison(method, imputed_data_folder,all_levels, all_levels_comb, cond_dist_complete, sample_id, impute_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiaxin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b739a31c4e4fe91c4490fb43f878478212ee9ffd58aeb08e90becf4444522421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
